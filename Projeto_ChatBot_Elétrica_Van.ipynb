{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrElDgokZ56OKtblrNCjnV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanleyC/Chatbot-El-trica/blob/main/Projeto_ChatBot_El%C3%A9trica_Van.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SKD do Google."
      ],
      "metadata": {
        "id": "2czytFsKfzkX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E1p92N1TfxXE"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import  usardata\n",
        "api_key= userdata.get (\"Chave Secreta\")\n",
        "\n",
        "\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "cuWfdSvGgtcY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos Disponiveis."
      ],
      "metadata": {
        "id": "A-D_QBzVhbQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models() :\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "pEDRoH2VhWz1",
        "outputId": "5efb9315-7e7b-4b0b-9593-6df274856ea1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta configurando os padroes de temperatura e quantidade de respostas possiveis\n"
      ],
      "metadata": {
        "id": "7x3UGu3OqIBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1 ,\n",
        "    \"temperature\" : 0.1,\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "uC6k8xP1liTP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando os parametros de segurança das respostas."
      ],
      "metadata": {
        "id": "U_0uMGdAqhiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"Harassment\" : \"BLOCK_NONE\" ,\n",
        "    \"Hate\" : \"BLOCK_NONE\" ,\n",
        "    \"Sexual\" : \"BLOCK_NONE\" ,\n",
        "    \"Dangerous\" : \"BLOCK_NONE\" ,\n",
        "}"
      ],
      "metadata": {
        "id": "fXvVyqBYoH_T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o modelo."
      ],
      "metadata": {
        "id": "1ZBC0vA9qdvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name= \"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "wDDP_3WmqSqg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerar o conteúdo\n"
      ],
      "metadata": {
        "id": "J3GzVDoHr7w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Formulas para calculo de dimensionamento elétrico residencial\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "Pix0GnsDsJ3m",
        "outputId": "2790add6-4de8-4cdc-a800-1d4777de76c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Cálculo de Carga Elétrica**\n",
            "\n",
            "* **Carga Total (Watts) = Suma de las cargas individuales de todos los electrodomésticos y dispositivos**\n",
            "* **Carga de Iluminación (Watts) = Número de bombillas x Potencia de cada bombilla**\n",
            "* **Carga de Motores (Watts) = Potencia nominal del motor x Factor de servicio**\n",
            "\n",
            "**Cálculo de Corriente**\n",
            "\n",
            "* **Corriente (Amperios) = Carga Total (Watts) / Voltaje (Voltios)**\n",
            "\n",
            "**Cálculo de Tamaño del Conductor**\n",
            "\n",
            "* **Tamaño del Conductor (AWG) = Tabla de Ampacidad del Conductor (basada en la corriente y el tipo de conductor)**\n",
            "\n",
            "**Cálculo de Tamaño del Disyuntor**\n",
            "\n",
            "* **Tamaño del Disyuntor (Amperios) = Corriente (Amperios) x Factor de Sobrecarga (1,25 para circuitos residenciales)**\n",
            "\n",
            "**Cálculo de Tamaño del Transformador**\n",
            "\n",
            "* **Tamaño del Transformador (kVA) = Carga Total (Watts) / 1000 x Factor de Potencia (0,8 para cargas residenciales)**\n",
            "\n",
            "**Cálculo de Caída de Voltaje**\n",
            "\n",
            "* **Caída de Voltaje (Voltios) = Corriente (Amperios) x Longitud del Conductor (Pies) x Resistencia del Conductor (Ohmios/1000 pies)**\n",
            "\n",
            "**Cálculo de Impedancia del Circuito**\n",
            "\n",
            "* **Impedancia del Circuito (Ohmios) = Resistencia del Conductor (Ohmios) + Reactancia Inductiva (Ohmios)**\n",
            "\n",
            "**Cálculo de Factor de Potencia**\n",
            "\n",
            "* **Factor de Potencia = Potencia Real (Watts) / Potencia Aparente (VA)**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora literalmente irar criar um chat\n"
      ],
      "metadata": {
        "id": "ktqZ3h9GtBkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "3gbwmOLVtFAJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando campo de prompt, criando a plataforma. != é mesmo que não igual , tudo que for digitado no input vai estar armazenado na variavel prompt,\n",
        "\"\\n\" = serve para pular 1 linha"
      ],
      "metadata": {
        "id": "1yMPGwMcuGu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Como posso ajudar? \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "   response = chat.send_message(prompt)\n",
        "   print(\"Resposta \" , response.text, \"\\n\" )\n",
        "   prompt = input(\"Como posso ajudar? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "snVqk18EtvIM",
        "outputId": "9d253d88-7cd6-4c45-d124-d8b83d96eff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Como posso ajudar? hi\n",
            "Resposta  Hello! How can I help you today? \n",
            "\n"
          ]
        }
      ]
    }
  ]
}